---
title: "ECAGP Air Quality Analysis"
author: "Cherry Pham and Scott Hersey + WQ"
date: "`r Sys.Date()`"
output: 
  rmdformats::readthedown:
    number_sections: true
    highlight: tango
    df_print: paged
    center: true
---

# Overview

This code gives an overview on: - Loading air quality data from QuantAQ
instruments - Performing initial summary analysis - Loading meteorology
data from public data - Combining air quality and meteorology data -
Conducting exploratory analysis on dynamics of air pollutants related to
time and meteorology



# AIR QUALITY DATA LOADING    

## Loading initial packages

```{r setup, include=FALSE}
# Check and install required packages if necessary
packages <- c("openair", "openairmaps", "leaflet", "dplyr", "chron", "timeDate", "data.table")
install.packages(packages[!sapply(packages, requireNamespace, quietly = TRUE)])

# Load required packages for data manipulation and analysis
invisible(sapply(packages, library, character.only = TRUE))

# Set options
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

## Load Air Quality Data file.

```{r}
# Load data frame
load("G:/My Drive/Air Partners/data/graphableData.RData")

# Set site names
mod_met <- mod_met %>% 
  mutate(name = ifelse(sn.x == "MOD-PM-01395", "ECAGP Eastway Site", "ECAGP Clinton Site"))

unique_sensors <- unique(mod_met$sn)

```

## Summary statistics

```{r}
# Looking briefly at summary statistics will give you a sense of the variables that you just loaded. This can also tip you off to things that might need attention. 
# What do you notice in these summary statistics?

summary(mod_met)

```

## Date formatting

```{r}
# Dates and times have a bunch of different possible formats. These formats can be the bane of your analysis existence. Thankfully the lubridate package (which we loaded above) makes things smoother. It even automatically detects daylight saving time!
mod_met$timestamp_local <- mod_met$timestamp_local.x
mod_met$date <- as.POSIXct(strptime(mod_met$timestamp_local, format = "%Y-%m-%d %H:%M:%S", tz = "America/New_York"))

```

## Time series

```{r}
# We'll spend a lot of time working with the openair package in our project and will get a more in-depth introduction in the next class. But we'll draw on one of its functions now.
# As you look at this time series, what sticks out to you?
# Where do you notice points that seem outside of what is reasonable?

unique_sensors <- unique(mod_met$sn)

for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met %>% filter(sn == sensor)
temp_plot = openair::timePlot(data_for_sensor, pollutant = c("pm1",  "pm25", "pm10"), y.relation = "free", main =title, key.header = "PM1 ug m-3")
}



```

# CLEANING STEPS

## Define threshold values
```{r}
# There are a lot of reasons why particular values in pollutant concentration may be untrustworthy. Namely, when power cycles in a sensor with electrochemical cells, concentration values are biased high until electrical currents stabilize. We'll use evidence we see in the timePlot from above to set threshods above which we'll remove values.

thresholds <- c(pm10 = 10000, 
                pm25 = 1000,
                pm1 = 500
                # no = 30,
                # no2 = 400,
                # co = 3000,
                # o3 = 200      
                )

```



## Remove outliers
```{r}

# Filter out according to defined thresholds

mod_met_filtered<-mod_met   # Create a new dataframe that will be filtered and preserve the original

# Iterate through columns and apply thresholds

for (pollutant in names(thresholds)) {
  threshold <- thresholds[[pollutant]]
 
  # Replace values above threshold with NA
  mod_met_filtered[, pollutant][mod_met_filtered[, pollutant] > threshold] <- NA

  # Replace values below zero with NA
  mod_met_filtered[, pollutant][mod_met_filtered[, pollutant] < 0] <- NA
}


```

## Sanity check time series - did you do your cleaning job?
```{r}
#timePlot(mod_met_filtered, pollutant = "co")

for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met %>% filter(sn == sensor)
temp_plot = openair::timePlot(data_for_sensor, pollutant = c("pm1",  "pm25", "pm10"), y.relation = "free", main =title, key.header = "PM1 ug m-3")
}
```


## Did you find any funky time periods that need to be removed from the data? If so, filter by Date range.
```{r}
# Filter the data to include only the desired time range
start_date <- as.Date("2023-10-2") # Start date for the funky time period
end_date <- as.Date("2023-10-25") # End date for the funky time period
mod_met_filtered_time <- mod_met_filtered[mod_met_filtered$date <= start_date | mod_met_filtered$date >= end_date, ]
```

# EXPLORATORY DATA ANALYSIS

We can answer a number of questions with air quality data. Some examples include: What is the air quality like now? Where is the air quality bad (now/typically)? When was AQ bad? What time of day should I (not) go outside? Where is my pollution coming from? How many bad pollution days were there this year? What fraction of the time was AQ good, bad, or in the middle? We'll use the R package openair to explore answers to these questions with data.

### Calendar Plots: When was air quality bad? How many bad days were there in the last year?
```{r}
# These can help identify specific dates or ranges of dates that had particularly high pollutant concentrations. You may want to look more closely at conspicuously elevated pollutant days.

for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met %>% filter(sn == sensor)
temp_plot = openair::calendarPlot(data_for_sensor, pollutant = "pm1", main =title, key.header = "PM1 ug m-3")
}

for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met %>% filter(sn == sensor)
temp_plot = openair::calendarPlot(data_for_sensor, pollutant = "pm25", main =title, key.header = "PM25 ug m-3")
}

for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met %>% filter(sn == sensor)
temp_plot = openair::calendarPlot(data_for_sensor, pollutant = "pm10", main =title, key.header = "PM10 ug m-3")
}

# calendarPlot(mod_met_filtered, pollutant = "pm1")
# calendarPlot(mod_met_filtered, pollutant = "pm25")
# calendarPlot(mod_met_filtered, pollutant = "pm10")
# calendarPlot(mod_met_filtered, pollutant = "pm10", limits = c(0,60), annotate='value')
# 
# 
# calendarPlot(mod_met_filtered, pollutant = "pm10", annotate = "value", limits = c(0,80),
# lim =50, cols = "Purples", col.lim = c("black", "orange"), layout = c(4, 3))


# Explore for 10 min - different pollutants; different limits; thresholds

```



## When PM1 was bad, what else was bad?

### Explore some scatterplots
```{r}
# install.packages("hexbin")
# scatterPlot(mod_met_filtered, x = "pm1", y = "pm25")
# scatterPlot(mod_met_filtered, x = "pm1", y = "pm25", method = "density", col = "jet")


for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met %>% filter(sn == sensor)
temp_plot = openair::scatterPlot(data_for_sensor, x = "pm1", y = "pm25", z = "pm10", avg.time='hour', method = "hexbin", type = c("season", "weekend"))
}

scatterPlot(mod_met_filtered, x = "pm1", y = "pm25", z = "pm10", avg.time='hour', method = "hexbin", linear = TRUE, smooth = FALSE, type = c("season", "weekend"))

```


## Diurnal Profiles: When is air quality (typically) bad? When is it typically (not) safe to go outside?
```{r}
# Diurnals: First look at a "typical day" for different pollutants
# Read openair manual to find different ways to use this function. Things that may be helpful: selectByDate; type (season, etc); normalise; subset


for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met_filtered %>% filter(sn == sensor)
temp_plot = openair::timeVariation(data_for_sensor, pollutant = c("pm1", "pm25", "pm10"), local.tz= "America/New_York", normalise = TRUE)
}

for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met_filtered %>% filter(sn == sensor)
myOutput = openair::timeVariation(data_for_sensor, pollutant = c("pm1", "pm25", "pm10"), local.tz= "America/New_York", normalise = TRUE, type = "season")
plot(myOutput, subset = "hour")
}


for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met_filtered %>% filter(sn == sensor)
myOutput = openair::timeVariation(data_for_sensor, pollutant = c("pm1", "pm25", "pm10"), local.tz= "America/New_York", type = "season")
plot(myOutput, subset = "hour")
}
#timeVariation(selectByDate(mod_met_filtered, month = c(1:5, 9:12)), pollutant = c('pm1', 'pm25', 'pm10'))
 
 # myOutput <- timeVariation(mod_met_filtered, pollutant = "pm1", statistic = "median", local.tz= "America/New_York", col = "firebrick", type = "season")#, subset = "hour") 
 # plot(myOutput, subset = "hour")

```

### TrendLevel - when was air quality typically bad?
```{r}
trendLevel(mod_met_filtered, x = "month", y = "hour", pollutant = "pm10", cols = "increment")
```



## Directional analysis of pollutants: Where is pollution bad? And where is pollution coming from?

### Create polar plots (and other things in that family)
```{r}
# this group of functions allows you to explore the relationship between wind speed, wind direction, and pollutant concentrations. They all give slightly different flavors of the relationship between pollutants and meteorology, so explore and see what stories emerge. 

# There are a bunch of different things you can define here - type (seasonal, etc), statistic (median, mean, max, standard deviation, etc), color scale limits, icon size, figure transparency, etc. In particular, the type and statistic inputs give you *very* different pictures of what's happening in an environment.

#polarPlot(mod_met_filtered, pollutant = "pm1", type="season")
#polarPlot(mod_met_filtered, pollutant = "pm10", type = "season", statistic = "weighted.mean")
#polarPlot(mod_met_filtered, pollutant = "no", limits = c(0,5), type = "season")
#polarFreq(mod_met_filtered, pollutant = "pm10")
#pollutionRose(mod_met_filtered, pollutant = "pm10")



for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met_filtered %>% filter(sn == sensor)
temp_plot = openair::polarAnnulus(mod_met_filtered, pollutant = "pm10")
}



for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met_filtered %>% filter(sn == sensor)
temp_plot = openair::polarCluster(mod_met_filtered, pollutant = "pm10", n.clusters = 4)
}

# Explore for 15 min

```


### Create Polar map plots
```{r}
#polarMap is an extension of polarPlot that places a polarPlot onto a map as an overlay. polarPlot is in a family of plots that include pollutionRose, polarAnnulus, polarFreq, percentileRose, and others that give slightly different visualizations of the same combined pollutant/met data. You should play with some of these too.

# There are a bunch of different things you can define here - type (seasonal, etc), statistic (median, mean, max, standard deviation, etc), color scale limits, icon size, figure transparency, etc. In particular, the type and statistic inputs give you *very* different pictures of what's happening in an environment.

polarMap(mod_met_filtered,
         pollutant = "pm1", 
         key.position = "bottom",
         key.header = "PM1 (ug m-3)", 
         key.footer = NULL, 
         x = "ws",
         latitude = "lat",
         longitude = "lon", 
         provider = "OpenStreetMap",
         #limits = c(0, 15),
         cols = "jet",
         alpha = 0.8,
         key = TRUE,
         iconWidth = 200,
         iconHeight = 200,
         fig.width = 4,
         fig.height = 4
         )


polarMap(mod_met_filtered,
         pollutant = "pm25", 
         key.position = "bottom",
         key.header = "PM25 (ug m-3)", 
         key.footer = NULL, 
         x = "ws",
         latitude = "lat",
         longitude = "lon", 
         provider = "OpenStreetMap",
  #       limits = c(0, 4),
         cols = "jet",
         alpha = 0.8,
         key = TRUE,
         iconWidth = 200,
         iconHeight = 200,
         fig.width = 4,
         fig.height = 4
         )


polarMap(mod_met_filtered,
         pollutant = "pm10", 
         key.position = "bottom",
         key.header = "PM10 (ug m-3)", 
         x = "ws",
         latitude = "lat",
         longitude = "lon", 
         provider = "OpenStreetMap",
       #  limits = c(0, 4),
         cols = "jet",
         key = TRUE,
         )



annulusMap(mod_met_filtered,
         pollutant = "pm1", 
         key.position = "bottom",
         key.header = "PM1 (ug m-3)", 
         period="hour",
         latitude = "lat",
         longitude = "lon", 
         provider = "OpenStreetMap",
       #  limits = c(0, 4),
         cols = "jet",
         key = TRUE,
         )

annulusMap(mod_met_filtered,
         pollutant = "pm25", 
         key.position = "bottom",
         key.header = "PM25 (ug m-3)", 
         period="hour",
         latitude = "lat",
         longitude = "lon", 
         provider = "OpenStreetMap",
       #  limits = c(0, 4),
         cols = "jet",
         key = TRUE,
         )

annulusMap(mod_met_filtered,
         pollutant = "pm10", 
         key.position = "bottom",
         key.header = "PM10 (ug m-3)", 
         period="hour",
         latitude = "lat",
         longitude = "lon", 
         provider = "OpenStreetMap",
       #  limits = c(0, 4),
         cols = "jet",
         key = TRUE,
         )

freqMap(mod_met_filtered,
         pollutant = "pm1", 
         key.position = "bottom",
         key.header = "PM1 (ug m-3)", 
         period="hour",
         latitude = "lat",
         longitude = "lon", 
         provider = "OpenStreetMap",
       #  limits = c(0, 4),
         cols = "jet",
         key = TRUE,
         )

percentileMap(mod_met_filtered,
         pollutant = "pm25", 
         key.position = "bottom",
         key.header = "PM25 (ug m-3)", 
         period="hour",
         latitude = "lat",
         longitude = "lon", 
         provider = "OpenStreetMap",
       #  limits = c(0, 4),
         cols = "jet",
         key = TRUE,
         )

percentileMap(mod_met_filtered,
         pollutant = "pm10", 
         key.position = "bottom",
         key.header = "PM10 (ug m-3)", 
         period="hour",
         latitude = "lat",
         longitude = "lon", 
         provider = "OpenStreetMap",
       #  limits = c(0, 4),
         cols = "jet",
         key = TRUE,
         )

# Explore for 15 min

```

# WQ
# More General EDA

## scatter plot - WIP, IDK yet

```{r}

# install.packages("hexbin")
# scatterPlot(mod_met_filtered, x = "pm1", y = "pm25")
# scatterPlot(mod_met_filtered, x = "pm1", y = "pm25", method = "density", col = "jet")


for (sensor in unique_sensors) {
title <- as.character(sensor)
data_for_sensor <- mod_met %>% filter(sn == sensor)
temp_plot = openair::scatterPlot(data_for_sensor, x = "pm1", y = "pm25", z = "pm10", avg.time='hour', method = "hexbin", type = c("season", "weekend"))
}

scatterPlot(mod_met_filtered, x = "pm1", y = "pm25", z = "pm10", avg.time='hour', method = "hexbin", linear = TRUE, smooth = FALSE, type = c("season", "weekend"))

```


## time series of all pm levels

 - Wasn't able to see the detail from PM1 and pm2.5
 - EPA Limit(pm2.5: 35, pm10: 150) (Blue), Average level without 12/16-12/18 Data (Red)
  - "This standard should not be exceeded more than once per year on average over three years"

```{r}
unique_sensors <- unique(mod_met$sn)

for (sensor in unique_sensors) {
  title <- as.character(sensor)
  data_for_sensor <- mod_met %>% filter(sn == sensor)
  
  if(nrow(data_for_sensor) == 0) next
  
  ## PM1 time series plot
  p_pm1 <- timePlot(data_for_sensor, pollutant = "pm1",
                    ylim = c(0, 70),
                    main = paste(title, "PM1"),
                    key.header = "PM1 ug m-3")
  
  ## PM2.5 time series plot without limit line
  p_pm25 <- timePlot(data_for_sensor, pollutant = "pm25",
                     ylim = c(0, 150),
                     main = paste(title, "PM2.5"),
                     key.header = "PM2.5 ug m-3")
  
  ## PM2.5 plot with a blue horizontal line at 35 µg/m³
  p_pm25_limit <- update(p_pm25,
                         panel = function(..., panel.groups = NULL) {
                           panel.xyplot(...)
                           panel.abline(h = 35, col = "blue", lwd = 2)
                         })
  
  ## PM10 time series plot without limit line
  p_pm10 <- timePlot(data_for_sensor, pollutant = "pm10",
                     ylim = c(0, 2500),
                     main = paste(title, "PM10"),
                     key.header = "PM10 ug m-3")
  
  ## PM10 plot with a blue horizontal line at 150 µg/m³
  p_pm10_limit <- update(p_pm10,
                         panel = function(..., panel.groups = NULL) {
                           panel.xyplot(...)
                           panel.abline(h = 150, col = "blue", lwd = 2)
                         })
}

```

## Histogram of Daily Average PM10 Levels

- EPA uses a 24-hour standard of 150 µg/m³.
- This standard should not be exceeded more than once per year on average over three years.
- shown that it has exceeded twice (2024-07-31 - 145.164072) within a 7 month period
- MOD-PM-01395	38.37543, MOD-PM-01396	45.22899, Overall Average PM10: 41.80221 

```{r}
library(dplyr)
library(lubridate)
library(ggplot2)

# Create a table of daily average PM10 levels for each sensor
daily_avg_pm10 <- mod_met %>%
  mutate(date = as.Date(mod_date_1min)) %>%   # Convert date-time to date
  group_by(sn, date) %>%
  summarise(avg_pm10 = mean(pm10, na.rm = TRUE)) %>%
  ungroup()

# Compute each sensor's overall average (mean of its daily averages)
sensor_avg <- daily_avg_pm10 %>%
  group_by(sn) %>%
  summarise(overall_avg = mean(avg_pm10, na.rm = TRUE)) %>%
  ungroup()

# Compute an overall average across sensors (mean of sensor averages)
overall_avg <- mean(sensor_avg$overall_avg, na.rm = TRUE)

# Print the table of sensor averages and the overall average
print(sensor_avg)
cat("Overall Average PM10:", overall_avg, "\n")

# Create a combined stacked histogram:
# - Fill is determined by sensor: light blue for one, dark blue for the other.
# - A red dashed line is drawn at 150 µg/m³.
# - Each sensor's overall average is added as a dotted vertical line.
p_stacked <- ggplot(daily_avg_pm10, aes(x = avg_pm10, fill = sn)) +
  geom_histogram(binwidth = 10, position = "stack", color = "black") +
  scale_fill_manual(values = c("lightblue", "darkblue")) +
  geom_vline(xintercept = 150, color = "red", linetype = "dashed", size = 1) +
  geom_vline(data = sensor_avg, aes(xintercept = overall_avg, color = sn),
             linetype = "dotted", size = 1) +
  scale_color_manual(values = c("lightblue", "darkblue")) +
  labs(title = "Stacked Histogram of Daily Average PM10 Levels by Sensor",
       x = "Daily Average PM10 (µg/m³)",
       y = "Frequency") +
  theme_minimal()

# Display the plot
print(p_stacked)

```
## Histogram of Daily Average PM2.5 Levels

- primary limit: 9.0 μg/m3, secondary limit: 15.0 μg/m (annual mean, averaged over 3 years)
- The average of 7 months period is 8.807473
- MOD-PM-01395	9.537952, MOD-PM-01396	8.076994, Overall Average PM2.5: 8.807473 	

```{r}
library(dplyr)
library(lubridate)
library(ggplot2)

# Create a table of daily average PM2.5 levels for each sensor
daily_avg_pm25 <- mod_met %>%
  mutate(date = as.Date(mod_date_1min)) %>%   # Convert date-time to date
  group_by(sn, date) %>%
  summarise(avg_pm25 = mean(pm25, na.rm = TRUE)) %>%
  ungroup()

# Compute each sensor's overall average (mean of its daily averages)
sensor_avg_pm25 <- daily_avg_pm25 %>%
  group_by(sn) %>%
  summarise(overall_avg = mean(avg_pm25, na.rm = TRUE)) %>%
  ungroup()

# Compute an overall average across sensors (mean of sensor-specific averages)
overall_avg_pm25 <- mean(sensor_avg_pm25$overall_avg, na.rm = TRUE)

# Print the table of sensor averages and the overall average for PM2.5
print(sensor_avg_pm25)
cat("Overall Average PM2.5:", overall_avg_pm25, "\n")

# Create a combined stacked histogram:
# - Fill color is determined by sensor: light blue for one, dark blue for the other.
# - A red dashed vertical line is drawn at 35 µg/m³.
# - Each sensor's overall average is added as a dotted vertical line in its corresponding color.
p_stacked_pm25 <- ggplot(daily_avg_pm25, aes(x = avg_pm25, fill = sn)) +
  geom_histogram(binwidth = 5, position = "stack", color = "black") +
  scale_fill_manual(values = c("lightblue", "darkblue")) +
  geom_vline(xintercept = 35, color = "red", linetype = "dashed", size = 1) +
  geom_vline(data = sensor_avg_pm25, aes(xintercept = overall_avg, color = sn),
             linetype = "dotted", size = 1) +
  scale_color_manual(values = c("lightblue", "darkblue")) +
  labs(title = "Stacked Histogram of Daily Average PM2.5 Levels by Sensor",
       x = "Daily Average PM2.5 (µg/m³)",
       y = "Frequency") +
  theme_minimal()

# Display the plot
print(p_stacked_pm25)


```

# 12/16-12/18 Data

```{r}
mod_met_dec16_18 <- mod_met_filtered %>%
  filter(mod_date_1min >= as.POSIXct("2024-12-16 00:00"),
         mod_date_1min <= as.POSIXct("2024-12-18 00:00"))
```

## Time series of 12/16-12/18 with epa limits

- when looking at the calendar plot of pm2.5, pm10 12/16-12/18 stand out
- missing info on sen 1395from dec 16 - dec 17 9am
- 1396 is more towards the Southeast and generally has higher numbers
- 1396 blue and red line are overlapped

```{r}
library(openair)
library(openairmaps)
library(leaflet)
library(dplyr)
library(chron)
library(timeDate)
library(data.table)

# Use the already-filtered data stored in mod_met_dec16_18
unique_sensors <- unique(mod_met_dec16_18$sn)

for (sensor in unique_sensors) {
  title <- as.character(sensor)
  # Filter the data for the current sensor from mod_met_dec16_18
  data_for_sensor <- mod_met_dec16_18 %>% filter(sn == sensor)
  
  cat("Sensor", sensor, "rows:", nrow(data_for_sensor), "\n")
  if(nrow(data_for_sensor) == 0) next
  
  # Compute the average PM10 level for this sensor using the filtered data
  avg_pm10 <- data_for_sensor %>%
    summarise(avg = mean(pm10, na.rm = TRUE)) %>%
    pull(avg)
  
  # Create the time series plot for PM10
  temp_plot <- openair::timePlot(data_for_sensor,
                                 pollutant = "pm10",
                                 y.lim = c(0, 2000),
                                 main = title,
                                 key.header = "PM10 ug m-3")
  
  # Update the plot by adding two horizontal lines:
  # - A red line at the average PM10 level (from mod_met_dec16_18)
  # - A blue line at 150 µg/m³
  updated_plot <- update(temp_plot,
                         panel = function(..., panel.groups = NULL) {
                           lattice::panel.xyplot(...)
                           lattice::panel.abline(h = avg_pm10, col = "red", lwd = 2)
                           lattice::panel.abline(h = 150, col = "blue", lwd = 2)
                         })
  
}

```

## Polar Plots of 12/16-12/18

- Both sensors are showing things from bottom right
- just a lot more on 1396

```{r}
library(openair)
library(dplyr)
library(gridExtra)
library(grid)
library(lattice)

unique_sensors <- unique(mod_met_dec16_18$sn)

for (sensor in unique_sensors) {
  title <- as.character(sensor)
  
  # Filter data for the sensor (data are already from 12/16 to 12/18)
  data_for_sensor <- mod_met_dec16_18 %>% filter(sn == sensor)
  
  cat("Sensor", sensor, "rows:", nrow(data_for_sensor), "\n")
  
  if (nrow(data_for_sensor) == 0)
    next
  
  # Create a title for the polar plots
  polar_title <- paste("Polar Plot: Sensor", title)
  
  # Create the polarAnnulus plot with the title
  polar_annulus_plot <- openair::polarAnnulus(data_for_sensor, 
                                              pollutant = "pm10", 
                                              k = 4, 
                                              main = polar_title)
  
  # Create the polarCluster plot with the title
  polar_cluster_plot <- openair::polarCluster(data_for_sensor, 
                                              pollutant = "pm10", 
                                              n.clusters = 4, 
                                              k = 4, 
                                              main = polar_title)
}

```
## Annulus polar plot map 2345623464356


```{r}
annulusMap(mod_met_dec16_18,
         pollutant = "pm25", 
         key.position = "bottom",
         key.header = "PM25 (ug m-3)", 
         period = "hour",
         latitude = "lat",
         longitude = "lon", 
         provider = "OpenStreetMap",
         k = 3,
         cols = "jet",
         key = TRUE)

annulusMap(mod_met_dec16_18,
         pollutant = "pm10", 
         key.position = "bottom",
         key.header = "PM10 (ug m-3)", 
         period = "hour",
         latitude = "lat",
         longitude = "lon", 
         provider = "OpenStreetMap",
         k = 3,
         cols = "jet",
         key = TRUE)

```

# Missing entries 

- When looking at time series, there are a substantial amount of gaps shown through straight lines

## Histogram of Entries by hour

- Shows how the entries jump up ~8th hour and gradually decreases at night
- This is shown to be the result of solar panels not having battery
- QuantAQ potentially has a program to upgrade the batteries for free

```{r}
library(dplyr)
library(lubridate)

hourly_counts <- mod_met %>% 
  mutate(hour = hour(mod_date_1min)) %>% 
  group_by(hour) %>% 
  summarise(entries = n()) %>% 
  arrange(desc(entries))

# Print the table
print(hourly_counts)
#########
library(ggplot2)

ggplot(hourly_counts, aes(x = hour, y = entries)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  scale_x_continuous(breaks = 0:23) +
  labs(title = "Hourly Distribution of Entries",
       x = "Hour of Day",
       y = "Number of Entries") +
  theme_minimal() +
  # Shade nighttime (0 to 6 AM)
  annotate("rect", xmin = -0.5, xmax = 6.5, ymin = 0, ymax = Inf,
           alpha = 0.2, fill = "gray") +
  # Shade nighttime (8 PM to midnight)
  annotate("rect", xmin = 19.5, xmax = 23.5, ymin = 0, ymax = Inf,
           alpha = 0.2, fill = "gray")
```

# Where to look now?

## Trendline without (12/16-12/18)

- For the month of Dec., it shows hours of 3-5 am lowering but still has a noticeable level of pm10
- Now it's emphasizes 0-2 am during the month of february which is something we will try to look into

```{r}
trend_data <- mod_met_filtered %>% 
  filter(mod_date_1min < as.POSIXct("2024-12-16 00:00") | 
         mod_date_1min > as.POSIXct("2024-12-18 00:00"))

trendLevel(trend_data, x = "month", y = "hour", pollutant = "pm10", cols = "increment",main = "Trendline Without (12/16-12/18)")
```
### Feb 

- there are only 6 days so the data is not fully represent the month of Febuary
- there is a large spike on the 5th skewing the data

```{r}
library(dplyr)
library(lubridate)
library(ggplot2)

# Create mod_met_feb: filter mod_met to only include February 2025 data
mod_met_feb <- mod_met %>%
  filter(year(mod_date_1min) == 2025, month(mod_date_1min) == 2)

# Create a time series plot for PM10 in February 2025
p_ts <- ggplot(mod_met_feb, aes(x = mod_date_1min, y = pm10)) +
  geom_line(color = "blue") +
  labs(title = "Time Series of PM10 in February 2025",
       x = "Date",
       y = "PM10 (µg/m³)") +
  theme_minimal()

# Display the plot
print(p_ts)

```
## Trendline without (12/16-12/18) and Feb.

- even after removing all the outlier data it still shows that dec has a high mean pm10 from 3-5

```{r}
library(dplyr)
library(lubridate)
library(openair)

trend_data <- mod_met_filtered %>% 
  filter((mod_date_1min < as.POSIXct("2024-12-16 00:00") | 
          mod_date_1min > as.POSIXct("2024-12-18 00:00")) &
         month(mod_date_1min) != 2)

trendLevel(trend_data, x = "month", y = "hour", pollutant = "pm10", cols = "increment",main = "Trendline Without (12/16-12/18) and Feb.")
```

## Polar Plots of PM10 by season

- Shows how it tends to be South East of both sensors 

```{r}
library(dplyr)
library(lubridate)
library(openair)

# Create a season variable:
#   Winter: December, January, February
#   Summer: June, July, August
#   Autumn: all other months
mod_met <- mod_met %>%
  mutate(season = case_when(
    month(mod_date_1min) %in% c(12, 1, 2) ~ "Winter",
    month(mod_date_1min) %in% c(6, 7, 8) ~ "Summer",
    TRUE ~ "Autumn"
  ))

unique_sensors <- unique(mod_met$sn)
seasons <- c("Winter", "Summer", "Autumn")

for(sensor in unique_sensors) {
  for(s in seasons) {
    # Filter data for the sensor and season
    data_subset <- mod_met %>% filter(sn == sensor, season == s)
    if(nrow(data_subset) == 0) next  # Skip if no data for this combination
    
    plot_title <- paste("Polar Plot:", sensor, "-", s, "PM10")
    
    # Create the polar plot for PM10 using all data (not aggregated hourly)
    p <- polarPlot(data_subset,
                   pollutant = "pm10",
                   main = plot_title)
    
  }
}
```

## Histograpms of 10 min + 60 min moving averages

```{r}
library(dplyr)
library(lubridate)
library(zoo)
library(ggplot2)

# --------------------------
# 10-Minute Moving Average
# --------------------------
daily_peaks_10 <- mod_met_filtered %>%
  arrange(mod_date_1min) %>%                              # ensure data is time-sorted
  mutate(date = as.Date(mod_date_1min),
         # Calculate 10-minute moving average (assuming 1 observation per minute)
         pm10_mavg = rollapply(pm10, width = 10, FUN = mean, fill = NA, align = "right")) %>%
  group_by(date) %>%
  summarise(daily_peak = max(pm10_mavg, na.rm = TRUE)) %>%
  ungroup()

# Print the table of daily peaks (10-min)
print(daily_peaks_10)

# Plot histogram of daily peaks (10-min moving average) using ggplot2
ggplot(daily_peaks_10, aes(x = daily_peak)) +
  geom_histogram(binwidth = 10, fill = "lightblue", color = "black") +
  labs(title = "Histogram of Daily Peak PM10 (10-min Moving Average)",
       x = "Daily Peak PM10 (µg/m³)",
       y = "Frequency") +
  theme_minimal()

# --------------------------
# 60-Minute Moving Average
# --------------------------
daily_peaks_60 <- mod_met_filtered %>%
  arrange(mod_date_1min) %>%                              # ensure data is time-sorted
  mutate(date = as.Date(mod_date_1min),
         # Calculate 60-minute moving average (assuming 1 observation per minute)
         pm10_mavg = rollapply(pm10, width = 60, FUN = mean, fill = NA, align = "right")) %>%
  group_by(date) %>%
  summarise(daily_peak = max(pm10_mavg, na.rm = TRUE)) %>%
  ungroup()

# Print the table of daily peaks (60-min)
print(daily_peaks_60)

# Plot histogram of daily peaks (60-min moving average) using ggplot2
ggplot(daily_peaks_60, aes(x = daily_peak)) +
  geom_histogram(binwidth = 10, fill = "lightblue", color = "black") +
  labs(title = "Histogram of Daily Peak PM10 (60-min Moving Average)",
       x = "Daily Peak PM10 (µg/m³)",
       y = "Frequency") +
  theme_minimal()

```

### time series of the top 10 days from moving averages


```{r}
library(dplyr)
library(lubridate)
library(openair)
library(gridExtra)
library(grid)

# Get the top 10 dates by daily peak PM10 from daily_peaks_60
top10 <- daily_peaks_60 %>%
  arrange(desc(daily_peak)) %>%
  slice(1:10)

# Create a list to store the plots
plot_list <- list()

for (i in 1:nrow(top10)) {
  current_date <- top10$date[i]
  plot_title <- paste("PM10 on", current_date)
  
  # Filter mod_met_filtered to the current date
  data_for_day <- mod_met_filtered %>% 
    filter(as.Date(mod_date_1min) == current_date)
  
  # Create the time series plot for PM10 on that date
  p <- timePlot(data_for_day,
                pollutant = "pm10",
                main = plot_title,
                key.header = "PM10 ug m-3")
  
  # Capture the plot as a grob and store in the list
  plot_list[[i]] <- grid.grabExpr(print(p))
}

# Combine the plots vertically into one image
combined_plots <- grid.arrange(grobs = plot_list, ncol = 1)


```

# hourly polar plots for pm 10

- K = 100 for seasonal plot
- K = 50 for hourly plot
- note that standard is k = 100
- when k = 100, sumemr data is gone, hours 00-07 in autumn are gone, and only 1396 13th hour in winter data


```{r}
library(dplyr)
library(lubridate)
library(openair)

# Helper function to assign season (returns "Winter", "Summer", or "Autumn")
get_season <- function(dates) {
  m <- month(dates)
  ifelse(m %in% c(12, 1, 2), "Winter",
         ifelse(m %in% c(6, 7, 8), "Summer",
                ifelse(m %in% c(9, 10, 11), "Autumn", NA)))
}

unique_sensors <- unique(mod_met_filtered$sn)

for (sensor in unique_sensors) {
  title <- as.character(sensor)
  
  # Filter data for the sensor and add a season column
  data_for_sensor <- mod_met_filtered %>% 
    filter(sn == sensor) %>% 
    mutate(season = get_season(mod_date_1min))
  
  if (nrow(data_for_sensor) == 0) next
  
  # Create a polar plot for PM10 conditioned by season (one plot per sensor)
  seasonal_plot <- polarPlot(data_for_sensor,
                             pollutant = "pm10",
                             type = "season",  # Automatically creates panels for each season present
                             k = 100,
                             main = paste("Polar Plot: Sensor", title, "by Season"))
  print(seasonal_plot)
  
  # Create an additional polar plot for PM10 conditioned by hour (one plot per sensor)
  hourly_plot <- polarPlot(data_for_sensor,
                           pollutant = "pm10",
                           type = "hour",  # Panels based on hour of the day (0-23)
                           k = 50,
                           main = paste("Polar Plot: Sensor", title, "by Hour"))
  print(hourly_plot)
}


```

# Diurnal Plots of pm 10


```{r}

library(dplyr)
library(lubridate)
library(openair)
library(gridExtra)
library(grid)

unique_sensors <- unique(mod_met_filtered$sn)

for (sensor in unique_sensors) {
  sensor_data <- mod_met_filtered %>% filter(sn == sensor)
  if(nrow(sensor_data) == 0) next
  
  # Compute the complete timeVariation output for PM10
  tv_out <- timeVariation(sensor_data, pollutant = "pm10")
  
  # Create each panel's plot with a custom title for clarity
  p_hour    <- plot(tv_out, subset = "hour", main = paste("Hourly Variation - Sensor", sensor))
  p_dayhour <- plot(tv_out, subset = "day.hour", main = paste("Day & Hour Variation - Sensor", sensor))
  p_day     <- plot(tv_out, subset = "day", main = paste("Weekday Variation - Sensor", sensor))
  p_month   <- plot(tv_out, subset = "month", main = paste("Monthly Variation - Sensor", sensor))
  
}
```

# Diurnal Plots of pm 2.5


```{r}

library(dplyr)
library(lubridate)
library(openair)
library(gridExtra)
library(grid)

unique_sensors <- unique(mod_met_filtered$sn)

for (sensor in unique_sensors) {
  sensor_data <- mod_met_filtered %>% filter(sn == sensor)
  if(nrow(sensor_data) == 0) next
  
  # Compute the complete timeVariation output for PM2.5
  tv_out <- timeVariation(sensor_data, pollutant = "pm25")
  
  # Create each panel's plot with a custom title for clarity
  p_hour    <- plot(tv_out, subset = "hour", main = paste("Hourly Variation - Sensor", sensor))
  p_dayhour <- plot(tv_out, subset = "day.hour", main = paste("Day & Hour Variation - Sensor", sensor))
  p_day     <- plot(tv_out, subset = "day", main = paste("Weekday Variation - Sensor", sensor))
  p_month   <- plot(tv_out, subset = "month", main = paste("Monthly Variation - Sensor", sensor))
  
}
```

#


```{r}

```

#


```{r}

```

#


```{r}


```













